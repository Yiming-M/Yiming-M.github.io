
    
    [{"authors":null,"categories":null,"content":"ðŸ‘‹ Hi, there! Iâ€™m Yiming Ma (é©¬ä¸€é“­ in Chinese). As a PhD candidate at MathSys CDT at the University of Warwick, my research focuses on multimodality in computer vision and its applications (e.g., in crowd counting and driver monitoring systems). I am passionate about bridging mathematics and deep learning to solve real-world problems.\n","date":1666051200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1666051200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"ðŸ‘‹ Hi, there! Iâ€™m Yiming Ma (é©¬ä¸€é“­ in Chinese). As a PhD candidate at MathSys CDT at the University of Warwick, my research focuses on multimodality in","tags":null,"title":"Yiming Ma","type":"authors"},{"authors":["Yiming Ma","Victor Sanchez","Tanaya Guha"],"categories":null,"content":"","date":1666051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666051200,"objectID":"06ccfccdef58a958add250d7ff529a39","permalink":"https://yiming-m.github.io/publication/icip2022/","publishdate":"2022-10-18T00:00:00Z","relpermalink":"/publication/icip2022/","section":"publication","summary":"State-of-the-art crowd counting models follow an encoder-decoder approach. Images are first processed by the encoder to extract features. Then, to account for perspective distortion, the highest-level feature map is fed to extra components to extract multiscale features, which are the input to the decoder to generate crowd densities. However, in these methods, features extracted at earlier stages during encoding are underutilised, and the multiscale modules can only capture a limited range of receptive fields, albeit with considerable computational cost. This paper proposes a novel crowd counting architecture (FusionCount), which exploits the adaptive fusion of a large majority of encoded features instead of relying on additional extraction components to obtain multiscale features. Thus, it can cover a more extensive scope of receptive field sizes and lower the computational cost. We also introduce a new channel reduction block, which can extract saliency information during decoding and further enhance the modelâ€™s performance. Experiments on two benchmark databases demonstrate that our model achieves state-of-the-art results with reduced computational complexity. PyTorch implementation of the model and weights trained on these two datasets are available at https://github.com/YimingMa/FusionCount.","tags":["Crowd Counting","Feature Fusion","Self Attention"],"title":"FusionCount: Efficient Crowd Counting via Multiscale Feature Fusion","type":"publication"}]